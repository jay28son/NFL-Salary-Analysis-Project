{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since all the data before 2019 is behind a login screen I need to code a way to logon to the website to grab the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The very first thing to do is import the python packages BeautifulSoup, requests, pandas, and creds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import creds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gathered the url and other information by using the inspect network element on google."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cookies = {\n",
    "    'MCPopupClosed': 'yes',\n",
    "    '_gid': 'GA1.2.1783712766.1660157331',\n",
    "    'PHPSESSID': '8lv90mcln6odafu4ct8v488tvloe3olj_premium',\n",
    "    '_gat': '1',\n",
    "    '_ga_3ZZTGEXZ3B': 'GS1.1.1660168631.8.1.1660175234.0',\n",
    "    '_ga': 'GA1.2.1968697907.1659831804',\n",
    "    '_gali': 'contactForm',\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    'authority': 'www.spotrac.com',\n",
    "    'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',\n",
    "    'accept-language': 'en-US,en;q=0.9',\n",
    "    'cache-control': 'max-age=0',\n",
    "    # Requests sorts cookies= alphabetically\n",
    "    # 'cookie': 'MCPopupClosed=yes; _gid=GA1.2.1783712766.1660157331; PHPSESSID=8lv90mcln6odafu4ct8v488tvloe3olj_premium; _gat=1; _ga_3ZZTGEXZ3B=GS1.1.1660168631.8.1.1660175234.0; _ga=GA1.2.1968697907.1659831804; _gali=contactForm',\n",
    "    'origin': 'https://www.spotrac.com',\n",
    "    'referer': 'https://www.spotrac.com/signin/',\n",
    "    'sec-ch-ua': '\".Not/A)Brand\";v=\"99\", \"Google Chrome\";v=\"103\", \"Chromium\";v=\"103\"',\n",
    "    'sec-ch-ua-mobile': '?0',\n",
    "    'sec-ch-ua-platform': '\"Windows\"',\n",
    "    'sec-fetch-dest': 'document',\n",
    "    'sec-fetch-mode': 'navigate',\n",
    "    'sec-fetch-site': 'same-origin',\n",
    "    'sec-fetch-user': '?1',\n",
    "    'upgrade-insecure-requests': '1',\n",
    "    'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/103.0.0.0 Safari/537.36',\n",
    "}\n",
    "\n",
    "data = {\n",
    "    'redirect': 'nfl/rankings/2018/cash/',\n",
    "    'email': creds.email,\n",
    "    'password': creds.password,\n",
    "}\n",
    "data2 = {\n",
    "    'ajax' : 'true',\n",
    "    'mobile': 'false'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the requests package and the data collected from earlier I log into the website and navigate to the page with the data I want to collect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = ('https://www.spotrac.com/nfl/rankings/2018/cash')\n",
    "with requests.session() as s:\n",
    "    s.post('https://www.spotrac.com/signin/submit/', data=data)\n",
    "    r = s.post(url, data=data2)\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created a list to attach the data to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_list = list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With BeautifulSoup I gather all the data from the table I wanted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfl_table = soup.find('table', class_ = 'datatable captracker noborder')\n",
    "for body in nfl_table.find_all('tbody'):\n",
    "    rows = body.find_all('tr')\n",
    "    for row in rows:\n",
    "         pl_name = row.find('a', class_ ='team-name').text.strip()\n",
    "         pl_team_name = row.find('div', class_ = 'rank-position').text.strip()\n",
    "         pl_position = row.find('td', class_ = 'center med').text.strip()\n",
    "         pl_salary = row.find_all('span', class_ = 'info')\n",
    "         for span in pl_salary:\n",
    "            span = span.text.replace('usd','').strip()      \n",
    "         rows_list.append([pl_name,pl_team_name,pl_position,span])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used the list from earlier and transformed it into a dataframe with column names using pandas and then converted the dataframe into a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>POS</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aaron Rodgers</td>\n",
       "      <td>GB</td>\n",
       "      <td>QB</td>\n",
       "      <td>$66,900,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jimmy Garoppolo</td>\n",
       "      <td>SF</td>\n",
       "      <td>QB</td>\n",
       "      <td>$41,950,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Khalil Mack</td>\n",
       "      <td>CHI</td>\n",
       "      <td>OLB</td>\n",
       "      <td>$41,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aaron Donald</td>\n",
       "      <td>LAR</td>\n",
       "      <td>DT</td>\n",
       "      <td>$40,892,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alex Smith</td>\n",
       "      <td>WAS</td>\n",
       "      <td>QB</td>\n",
       "      <td>$40,000,000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Name Team  POS       Salary\n",
       "0    Aaron Rodgers   GB   QB  $66,900,000\n",
       "1  Jimmy Garoppolo   SF   QB  $41,950,000\n",
       "2      Khalil Mack  CHI  OLB  $41,000,000\n",
       "3     Aaron Donald  LAR   DT  $40,892,000\n",
       "4       Alex Smith  WAS   QB  $40,000,000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nfl=pd.DataFrame(rows_list,columns=['Name','Team','POS', 'Salary'])\n",
    "df_nfl.index = np.arange(1, len(df_nfl) + 1)\n",
    "df_nfl.to_csv('NFL 2018 Salary.csv', index=False)\n",
    "nfl_file=pd.read_csv('NFL 2018 Salary.csv')\n",
    "df_nfl.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88d28bfc7eb9c4a2b365ceaf5f4f335dcd0cb22dbe842829c0399eb707f6c21d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
